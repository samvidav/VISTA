library(ggplot2)
theme_set(theme_bw())
library(UniProt.ws)
library(topGO)
library(reticulate)
library(networkDynamic)
library(RColorBrewer)
library(ndtv)
library(tsna)
library(shiny)
library(zip)
set.seed(123)
##### GET AND CLEAN DATA ####
links_filename <- list.files(path=".", pattern= "edges*")[1]
nodes_filename <- "nodes.csv"
links <- read.csv(links_filename, header=T, as.is=T, sep=",", stringsAsFactors = F)
nodes <- read.csv(nodes_filename, header=T, as.is=T, sep=",", stringsAsFactors = F)
# ensure all values are filled
links[is.na(links)] <- 0
# get edge weight threshold from input filename (GUI)
# get numeric portion of filename
CUTOFF_THRESHOLD <- as.numeric(unlist(regmatches(links_filename,
gregexpr("[[:digit:]]+\\.*[[:digit:]]*",
links_filename))))
# weight threshold is set lower than cutoff to prevent artificial on-off behavior
if (CUTOFF_THRESHOLD <= 0.1 ) {
WEIGHT_THRESHOLD <- CUTOFF_THRESHOLD
} else {
WEIGHT_THRESHOLD <- CUTOFF_THRESHOLD - 0.1
}
# get timepoint information from column names
num_link_attr <- ncol(links)
timepoints <- unique(as.numeric(unlist(regmatches(colnames(links)[3:num_link_attr],
gregexpr("[[:digit:]]+\\.*[[:digit:]]*",
colnames(links)[3:num_link_attr])))))
NUM_TPS <- length(timepoints)
# set interval length to smallest interval between timepoints
interval <- {}
for (i in 1:(NUM_TPS-1)) {
interval[i] <- timepoints[i+1] - timepoints[i]
}
INTERVAL <- min(interval)
# rename node columns
LOC_PROV <- F
if (ncol(nodes) == 3) {
colnames(nodes) <- c("accession", "gene_name", "taxid")
} else {
LOC_PROV <- T
colnames(nodes) <- c("accession", "gene_name", "taxid", "localization")
}
# rename link columns
colnames(links)[c(1,2)] <- c("bait_accession", "prey_accession")
ABUND_PROV <- F
if (num_link_attr == NUM_TPS+2) {
colnames(links)[3:num_link_attr] <- paste("w", timepoints, sep="")
} else {
ABUND_PROV <- T
cnames <- c()
for (i in 1:NUM_TPS) {
cnames <- c(cnames, paste("w", timepoints[i], sep=""))
cnames <- c(cnames, paste("a", timepoints[i], sep=""))
}
colnames(links)[3:num_link_attr] <- cnames
}
# only keep links where at least one timepoint is over the cutoff threshold
keep_links <- apply(links[, paste("w", timepoints, sep="")], 1,
function(x) { sum(x >= CUTOFF_THRESHOLD) > 0 } )
links <- links[keep_links, ]
# remove duplicate nodes and links
nodes <- nodes[!duplicated(nodes$accession), ]
nodes <- nodes[nodes$accession %in% links$bait_accession |
nodes$accession %in% links$prey_accession, ]
NUM_NODES <- dim(nodes)[1]
links <- links[!duplicated(links[, c("bait_accession", "prey_accession")]), ]
NUM_LINKS <- dim(links)[1]
# assign unique ids to nodes
nodes$id <- c(1:NUM_NODES)
rownames(nodes) <- nodes$id
# attach ids and gene names to links
links <- merge(links, nodes[, c("accession", "gene_name", "id")], by.x="bait_accession",
by.y="accession")
colnames(links)[c(ncol(links)-1, ncol(links))] <- c("bait_gene_name", "bait_id")
links <- merge(links, nodes[, c("accession", "gene_name", "id")], by.x="prey_accession",
by.y="accession")
colnames(links)[c(ncol(links)-1, ncol(links))] <- c("prey_gene_name", "prey_id")
BAIT_IDS <- unique(links$bait_id)
NUM_BAITS <- length(BAIT_IDS)
TAXIDS <- unique(nodes$taxid)
##### CALCULATE SHARED NODES ####
for (tp in timepoints) {
shared_tp <- c(mode='numeric', length=NUM_NODES)
shared_bait_tp <- c("", length=NUM_NODES)
for (i in 1:NUM_NODES) {
shared_tp[i] <- sum(links[links$prey_accession == nodes$accession[i],
paste('w', tp, sep="")] >= WEIGHT_THRESHOLD)
if (shared_tp[i] > 0) {
shared_baits <- links[which(links$prey_accession == nodes$accession[i] &
links[, paste('w', tp, sep="")] >= WEIGHT_THRESHOLD),
"bait_gene_name"]
shared_bait_tp[i] <- paste0(shared_baits, collapse = "; ")
} else { shared_bait_tp[i] <- "" }
}
nodes <- cbind(nodes, shared_tp)
colnames(nodes)[ncol(nodes)] <- paste("shared_", tp, sep="")
nodes[, ncol(nodes)] <- as.character(nodes[, ncol(nodes)])
nodes <- cbind(nodes, shared_bait_tp)
colnames(nodes)[ncol(nodes)] <- paste("shared_baits_", tp, sep="")
nodes[, ncol(nodes)] <- as.character(nodes[, ncol(nodes)])
}
##### CORUM COMPLEX INFORMATION ####
corum_complexes <- read.table("coreComplexes.txt", header = T, sep = "\t", quote = "",
fill = T, stringsAsFactors = F)
corum_complexes <- corum_complexes[, c("ComplexName", "subunits.UniProt.IDs.")]
list_complexes <- strsplit(corum_complexes[, "subunits.UniProt.IDs."], ";")
names(list_complexes) <- corum_complexes$ComplexName
# only keep complexes with at least 3 members (no duplexes)
list_complexes <- Filter(function(x) length(x) > 2, list_complexes)
# only keep complexes with at least 40% of its members in the provided dataset
keep_function <- function(x) {
if (sum(x %in% nodes$accession) / length(x) >= 0.4 ) {
return (TRUE)
} else { return (FALSE) }
}
list_complexes <- Filter(keep_function, list_complexes)
chr2string <- function(x) {
gene_names <- nodes[nodes$accession %in% x, "gene_name"]
return (paste0(gene_names, collapse="; "))
}
percent_detected <- function(x) {
return ( sum(x %in% nodes$accession) / length(x) )
}
# output complexes table (for download)
detected_complexes <- cbind.data.frame(names(list_complexes),
sapply(list_complexes, percent_detected),
sapply(list_complexes, chr2string))
colnames(detected_complexes) <- c("Complex Name", "Fraction of Complex Detected",
"Detected Complex Members")
detected_complexes <- detected_complexes[order(-detected_complexes$`Fraction of Complex Detected`), ]
# annotate nodes with complex membership
complex_membership <- rep("", NUM_NODES)
for (i in 1:NUM_NODES) {
complexes <- which(grepl(nodes$gene_name[i], detected_complexes$`Detected Complex Members`))
if (length(complexes) > 0) {
complex_membership[i] <- paste0(names(list_complexes)[complexes], collapse="; ")
}
}
nodes$complexes <- complex_membership
##### CLUSTER PROTEINS BASED ON ABUNDANCES OVER TIME ####
# if abundances are provided
if (ABUND_PROV) {
links$cluster = NA
relative_abundances <- {}
for (bait_id in BAIT_IDS) {
bait_gene_name <- nodes[which(nodes$id == bait_id), "gene_name"]
# get abundances for all nodes associated with this bait (except bait itself)
abundances <- links[which(links$bait_id == bait_id & links$prey_id != bait_id),
c("prey_gene_name", paste("a", timepoints, sep=""))]
# scale values from 0 to 1
zero2one <- function(x) {
return ((x - min(x)) / (max(x) - min(x)) )
}
# scale values to max 1
maxOne <- function(x) {
return ( x / max(x) )
}
to_scale <- abundances[, c(2:ncol(abundances))]
abundances[, c(2:ncol(abundances))] <- t(apply(to_scale, 1, maxOne))
# calculate pca
abundances[is.na(abundances)] <- 0
# only calculate pca on columns with differential expresson
comp_pca <- which(dim(table(abundances[, c(2:ncol(abundances))])) > 1) + 1
abundances_pca <- prcomp(scale(abundances[, comp_pca]))
# find number of clusters as number of PCs that explain over 90% of the variance
eigs <- abundances_pca$sdev^2
pve <- eigs / sum(eigs) # get percent of variance explained by each PC
total_pve <- 0
for (i in 1:length(pve)) {
total_pve <- total_pve + pve[i]
if (total_pve >= 0.9) { break }
}
num_clusters <- i
# k-means clustering
clusters <- kmeans(abundances[, c(2:ncol(abundances))], num_clusters)
abundances <- cbind(abundances, clusters$cluster)
colnames(abundances)[ncol(abundances)] <- "cluster"
# add cluster numbers to links
for (i in 1:dim(abundances)[1]) {
links$cluster[which(links$prey_gene_name == abundances$prey_gene_name[i] &
links$bait_gene_name == bait_gene_name)] <-
abundances$cluster[i]
}
# save relative abundances to plot
abundances$bait_gene_name <- bait_gene_name
relative_abundances <- rbind(relative_abundances, abundances)
}
clusterPlot <- function(bait_id) {
# plot profiles of proteins split by cluster
melt_abund <- {}
bait_gene_name <- nodes$gene_name[which(nodes$id == bait_id)]
abundances <- relative_abundances[which(relative_abundances$bait_gene_name ==
bait_gene_name), ]
for (i in rownames(abundances)) {
new <- cbind.data.frame(timepoints, rep(abundances[i, "cluster"], NUM_TPS))
new <- cbind.data.frame(new, rep(abundances[i, "prey_gene_name"], NUM_TPS))
new <- cbind.data.frame(new, as.vector(t(abundances[i, paste("a", timepoints, sep="")])))
melt_abund <- rbind(melt_abund, new)
}
colnames(melt_abund) <- c("time", "cluster", "prey_gene_name", "abundance")
rownames(melt_abund) <- 1:dim(melt_abund)[1]
print(ggplot(data=melt_abund, aes(x=time, y=abundance, group=prey_gene_name)) +
geom_line(aes(color=as.factor(cluster))) +
geom_point(aes(color=as.factor(cluster))) +
scale_x_continuous(breaks = timepoints) +
labs(title=paste("Bait", bait_gene_name), x="Time", y="Scaled Relative Abundance",
color="Cluster") +
facet_wrap(~as.factor(cluster)))
}
}
links$cluster = NA
relative_abundances <- {}
bait_gene_name <- nodes[which(nodes$id == bait_id), "gene_name"]
abundances <- links[which(links$bait_id == bait_id & links$prey_id != bait_id),
c("prey_gene_name", paste("a", timepoints, sep=""))]
View(abundances)
# scale values from 0 to 1
zero2one <- function(x) {
return ((x - min(x)) / (max(x) - min(x)) )
}
# scale values to max 1
maxOne <- function(x) {
return ( x / max(x) )
}
to_scale <- abundances[, c(2:ncol(abundances))]
abundances[, c(2:ncol(abundances))] <- t(apply(to_scale, 1, maxOne))
View(abundances)
abundances[is.na(abundances)] <- 0
colSums(abundances[, 2:ncol(abundances)])
length(unique(abundances[, 2:ncol(abundances)]))
unique(abundances[, 2:ncol(abundances)])
dim(table(abundances[, 2]))
dim(table(abundances[, 2:5]))
comp_pca <- c()
for (column in 2:ncol(abundances)) {
if (dim(table(abundances[, columns])) > 1) { comp_pca <- c(comp_pca, column) }
}
comp_pca <- c()
for (column in 2:ncol(abundances)) {
if (dim(table(abundances[, columns])) > 1) { comp_pca <- append(comp_pca, column) }
}
comp_pca <- {}
for (column in 2:ncol(abundances)) {
if (dim(table(abundances[, columns])) > 1) {
comp_pca <- append(comp_pca, column)
}
}
comp_pca <- c()
for (column in 2:ncol(abundances)) {
if (dim(table(abundances[, column])) > 1) {
comp_pca <- c(comp_pca, column)
}
}
abundances_pca <- prcomp(scale(abundances[, comp_pca]))
##### GET AND CLEAN DATA ####
links_filename <- list.files(path=".", pattern= "edges*")[1]
nodes_filename <- "nodes.csv"
links <- read.csv(links_filename, header=T, as.is=T, sep=",", stringsAsFactors = F)
nodes <- read.csv(nodes_filename, header=T, as.is=T, sep=",", stringsAsFactors = F)
# ensure all values are filled
links[is.na(links)] <- 0
# get edge weight threshold from input filename (GUI)
# get numeric portion of filename
CUTOFF_THRESHOLD <- as.numeric(unlist(regmatches(links_filename,
gregexpr("[[:digit:]]+\\.*[[:digit:]]*",
links_filename))))
# weight threshold is set lower than cutoff to prevent artificial on-off behavior
if (CUTOFF_THRESHOLD <= 0.1 ) {
WEIGHT_THRESHOLD <- CUTOFF_THRESHOLD
} else {
WEIGHT_THRESHOLD <- CUTOFF_THRESHOLD - 0.1
}
# get timepoint information from column names
num_link_attr <- ncol(links)
timepoints <- unique(as.numeric(unlist(regmatches(colnames(links)[3:num_link_attr],
gregexpr("[[:digit:]]+\\.*[[:digit:]]*",
colnames(links)[3:num_link_attr])))))
NUM_TPS <- length(timepoints)
# set interval length to smallest interval between timepoints
interval <- {}
for (i in 1:(NUM_TPS-1)) {
interval[i] <- timepoints[i+1] - timepoints[i]
}
INTERVAL <- min(interval)
# rename node columns
LOC_PROV <- F
if (ncol(nodes) == 3) {
colnames(nodes) <- c("accession", "gene_name", "taxid")
} else {
LOC_PROV <- T
colnames(nodes) <- c("accession", "gene_name", "taxid", "localization")
}
# rename link columns
colnames(links)[c(1,2)] <- c("bait_accession", "prey_accession")
ABUND_PROV <- F
if (num_link_attr == NUM_TPS+2) {
colnames(links)[3:num_link_attr] <- paste("w", timepoints, sep="")
} else {
ABUND_PROV <- T
cnames <- c()
for (i in 1:NUM_TPS) {
cnames <- c(cnames, paste("w", timepoints[i], sep=""))
cnames <- c(cnames, paste("a", timepoints[i], sep=""))
}
colnames(links)[3:num_link_attr] <- cnames
}
# only keep links where at least one timepoint is over the cutoff threshold
keep_links <- apply(links[, paste("w", timepoints, sep="")], 1,
function(x) { sum(x >= CUTOFF_THRESHOLD) > 0 } )
links <- links[keep_links, ]
# remove duplicate nodes and links
nodes <- nodes[!duplicated(nodes$accession), ]
nodes <- nodes[nodes$accession %in% links$bait_accession |
nodes$accession %in% links$prey_accession, ]
NUM_NODES <- dim(nodes)[1]
links <- links[!duplicated(links[, c("bait_accession", "prey_accession")]), ]
NUM_LINKS <- dim(links)[1]
# assign unique ids to nodes
nodes$id <- c(1:NUM_NODES)
rownames(nodes) <- nodes$id
# attach ids and gene names to links
links <- merge(links, nodes[, c("accession", "gene_name", "id")], by.x="bait_accession",
by.y="accession")
colnames(links)[c(ncol(links)-1, ncol(links))] <- c("bait_gene_name", "bait_id")
links <- merge(links, nodes[, c("accession", "gene_name", "id")], by.x="prey_accession",
by.y="accession")
colnames(links)[c(ncol(links)-1, ncol(links))] <- c("prey_gene_name", "prey_id")
BAIT_IDS <- unique(links$bait_id)
NUM_BAITS <- length(BAIT_IDS)
TAXIDS <- unique(nodes$taxid)
##### CALCULATE SHARED NODES ####
for (tp in timepoints) {
shared_tp <- c(mode='numeric', length=NUM_NODES)
shared_bait_tp <- c("", length=NUM_NODES)
for (i in 1:NUM_NODES) {
shared_tp[i] <- sum(links[links$prey_accession == nodes$accession[i],
paste('w', tp, sep="")] >= WEIGHT_THRESHOLD)
if (shared_tp[i] > 0) {
shared_baits <- links[which(links$prey_accession == nodes$accession[i] &
links[, paste('w', tp, sep="")] >= WEIGHT_THRESHOLD),
"bait_gene_name"]
shared_bait_tp[i] <- paste0(shared_baits, collapse = "; ")
} else { shared_bait_tp[i] <- "" }
}
nodes <- cbind(nodes, shared_tp)
colnames(nodes)[ncol(nodes)] <- paste("shared_", tp, sep="")
nodes[, ncol(nodes)] <- as.character(nodes[, ncol(nodes)])
nodes <- cbind(nodes, shared_bait_tp)
colnames(nodes)[ncol(nodes)] <- paste("shared_baits_", tp, sep="")
nodes[, ncol(nodes)] <- as.character(nodes[, ncol(nodes)])
}
##### CORUM COMPLEX INFORMATION ####
corum_complexes <- read.table("coreComplexes.txt", header = T, sep = "\t", quote = "",
fill = T, stringsAsFactors = F)
corum_complexes <- corum_complexes[, c("ComplexName", "subunits.UniProt.IDs.")]
list_complexes <- strsplit(corum_complexes[, "subunits.UniProt.IDs."], ";")
names(list_complexes) <- corum_complexes$ComplexName
# only keep complexes with at least 3 members (no duplexes)
list_complexes <- Filter(function(x) length(x) > 2, list_complexes)
# only keep complexes with at least 40% of its members in the provided dataset
keep_function <- function(x) {
if (sum(x %in% nodes$accession) / length(x) >= 0.4 ) {
return (TRUE)
} else { return (FALSE) }
}
list_complexes <- Filter(keep_function, list_complexes)
chr2string <- function(x) {
gene_names <- nodes[nodes$accession %in% x, "gene_name"]
return (paste0(gene_names, collapse="; "))
}
percent_detected <- function(x) {
return ( sum(x %in% nodes$accession) / length(x) )
}
# output complexes table (for download)
detected_complexes <- cbind.data.frame(names(list_complexes),
sapply(list_complexes, percent_detected),
sapply(list_complexes, chr2string))
colnames(detected_complexes) <- c("Complex Name", "Fraction of Complex Detected",
"Detected Complex Members")
detected_complexes <- detected_complexes[order(-detected_complexes$`Fraction of Complex Detected`), ]
# annotate nodes with complex membership
complex_membership <- rep("", NUM_NODES)
for (i in 1:NUM_NODES) {
complexes <- which(grepl(nodes$gene_name[i], detected_complexes$`Detected Complex Members`))
if (length(complexes) > 0) {
complex_membership[i] <- paste0(names(list_complexes)[complexes], collapse="; ")
}
}
nodes$complexes <- complex_membership
##### CLUSTER PROTEINS BASED ON ABUNDANCES OVER TIME ####
# if abundances are provided
if (ABUND_PROV) {
links$cluster = NA
relative_abundances <- {}
for (bait_id in BAIT_IDS) {
bait_gene_name <- nodes[which(nodes$id == bait_id), "gene_name"]
# get abundances for all nodes associated with this bait (except bait itself)
abundances <- links[which(links$bait_id == bait_id & links$prey_id != bait_id),
c("prey_gene_name", paste("a", timepoints, sep=""))]
# scale values from 0 to 1
zero2one <- function(x) {
return ((x - min(x)) / (max(x) - min(x)) )
}
# scale values to max 1
maxOne <- function(x) {
return ( x / max(x) )
}
to_scale <- abundances[, c(2:ncol(abundances))]
abundances[, c(2:ncol(abundances))] <- t(apply(to_scale, 1, maxOne))
# calculate pca
abundances[is.na(abundances)] <- 0
# only calculate pca on columns with differential expresson
comp_pca <- c()
for (column in 2:ncol(abundances)) {
if (dim(table(abundances[, column])) > 1) {
comp_pca <- c(comp_pca, column)
}
}
abundances_pca <- prcomp(scale(abundances[, comp_pca]))
# find number of clusters as number of PCs that explain over 90% of the variance
eigs <- abundances_pca$sdev^2
pve <- eigs / sum(eigs) # get percent of variance explained by each PC
total_pve <- 0
for (i in 1:length(pve)) {
total_pve <- total_pve + pve[i]
if (total_pve >= 0.9) { break }
}
num_clusters <- i
# k-means clustering
clusters <- kmeans(abundances[, c(2:ncol(abundances))], num_clusters)
abundances <- cbind(abundances, clusters$cluster)
colnames(abundances)[ncol(abundances)] <- "cluster"
# add cluster numbers to links
for (i in 1:dim(abundances)[1]) {
links$cluster[which(links$prey_gene_name == abundances$prey_gene_name[i] &
links$bait_gene_name == bait_gene_name)] <-
abundances$cluster[i]
}
# save relative abundances to plot
abundances$bait_gene_name <- bait_gene_name
relative_abundances <- rbind(relative_abundances, abundances)
}
clusterPlot <- function(bait_id) {
# plot profiles of proteins split by cluster
melt_abund <- {}
bait_gene_name <- nodes$gene_name[which(nodes$id == bait_id)]
abundances <- relative_abundances[which(relative_abundances$bait_gene_name ==
bait_gene_name), ]
for (i in rownames(abundances)) {
new <- cbind.data.frame(timepoints, rep(abundances[i, "cluster"], NUM_TPS))
new <- cbind.data.frame(new, rep(abundances[i, "prey_gene_name"], NUM_TPS))
new <- cbind.data.frame(new, as.vector(t(abundances[i, paste("a", timepoints, sep="")])))
melt_abund <- rbind(melt_abund, new)
}
colnames(melt_abund) <- c("time", "cluster", "prey_gene_name", "abundance")
rownames(melt_abund) <- 1:dim(melt_abund)[1]
print(ggplot(data=melt_abund, aes(x=time, y=abundance, group=prey_gene_name)) +
geom_line(aes(color=as.factor(cluster))) +
geom_point(aes(color=as.factor(cluster))) +
scale_x_continuous(breaks = timepoints) +
labs(title=paste("Bait", bait_gene_name), x="Time", y="Scaled Relative Abundance",
color="Cluster") +
facet_wrap(~as.factor(cluster)))
}
}
